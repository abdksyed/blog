<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>DE⫶TR – End-to-End Object Detection with Transformers | Explore Thoughts</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="DE⫶TR – End-to-End Object Detection with Transformers" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An End to End pipeline for Object Detection." />
<meta property="og:description" content="An End to End pipeline for Object Detection." />
<link rel="canonical" href="https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/02/ObjectDetection-DETR.html" />
<meta property="og:url" content="https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/02/ObjectDetection-DETR.html" />
<meta property="og:site_name" content="Explore Thoughts" />
<meta property="og:image" content="https://abdksyed.github.io/blog/images/CustomDataset/Predicted.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-02T00:00:00-05:00" />
<script type="application/ld+json">
{"image":"https://abdksyed.github.io/blog/images/CustomDataset/Predicted.png","url":"https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/02/ObjectDetection-DETR.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/02/ObjectDetection-DETR.html"},"headline":"DE⫶TR – End-to-End Object Detection with Transformers","dateModified":"2021-10-02T00:00:00-05:00","datePublished":"2021-10-02T00:00:00-05:00","description":"An End to End pipeline for Object Detection.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://abdksyed.github.io/blog/feed.xml" title="Explore Thoughts" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Explore Thoughts</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">DE⫶TR -- End-to-End Object Detection with Transformers</h1><p class="page-description">An End to End pipeline for Object Detection.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-02T00:00:00-05:00" itemprop="datePublished">
        Oct 2, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Custom Dataset">Custom Dataset</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Object Detection">Object Detection</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Panoptic Segmentation">Panoptic Segmentation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#COCO">COCO</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#DETR">DETR</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/abdksyed/blog/tree/master/_notebooks/2021-10-02-ObjectDetection-DETR.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/abdksyed/blog/master?filepath=_notebooks%2F2021-10-02-ObjectDetection-DETR.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/abdksyed/blog/blob/master/_notebooks/2021-10-02-ObjectDetection-DETR.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Creating-Dataset-Script-for-DETR">Creating Dataset Script for DETR </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Transformations">Transformations </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Model-and-Training">Model and Training </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Fine-Tuning">Fine Tuning </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Inference-and-Metrics">Inference and Metrics </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Metrics">Metrics </a>
<ul>
<li class="toc-entry toc-h3"><a href="#mAP-(mean-Average-Precision)">mAP (mean Average Precision) </a></li>
<li class="toc-entry toc-h3"><a href="#IoU-(Intersection-over-Union)">IoU (Intersection over Union) </a></li>
<li class="toc-entry toc-h3"><a href="#mean-Average-Recall">mean Average Recall </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Some-Cool-Sample-Results">Some Cool Sample Results </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-10-02-ObjectDetection-DETR.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/Cover.png" alt="Cool"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The code has been forked from this <a href="https://www.youtube.com/watch?v=RkhXoj_Vvr4">awesome video tutorial</a>, and the here is the <a href="https://github.com/thedeepreader/detr_tutorial">git repo</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Creating-Dataset-Script-for-DETR">
<a class="anchor" href="#Creating-Dataset-Script-for-DETR" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating Dataset Script for DETR<a class="anchor-link" href="#Creating-Dataset-Script-for-DETR"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># detr/datasets/construction.py</span>
<span class="k">class</span> <span class="nc">ConstructionDetection</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CocoDetection</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_file</span><span class="p">,</span> <span class="n">transforms</span><span class="p">,</span> <span class="n">return_masks</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConstructionDetection</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_file</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare</span> <span class="o">=</span> <span class="n">ConvertCocoPolysToMask</span><span class="p">(</span><span class="n">return_masks</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">ConstructionDetection</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
        <span class="n">image_id</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ids</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'image_id'</span><span class="p">:</span> <span class="n">image_id</span><span class="p">,</span> <span class="s1">'annotations'</span><span class="p">:</span> <span class="n">target</span><span class="p">}</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transforms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transforms</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our dataset class <code>ConstructionDetection</code> is inherited from <code>torchvision.datasets.CocoDetection</code>, and it does all the weight lifting of calling images and the labels. We than apply our transformations if any to the images, and serve the tuple of images and labels.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transformations">
<a class="anchor" href="#Transformations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transformations<a class="anchor-link" href="#Transformations"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># detr/datasets/construction.py</span>

<span class="kn">import</span> <span class="nn">datasets.transforms</span> <span class="k">as</span> <span class="nn">T</span>

<span class="n">normalize</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">])</span>

<span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">544</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="mi">608</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">672</span><span class="p">,</span> <span class="mi">704</span><span class="p">,</span> <span class="mi">736</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">800</span><span class="p">]</span>

<span class="k">if</span> <span class="n">image_set</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">T</span><span class="o">.</span><span class="n">RandomSelect</span><span class="p">(</span>
            <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">([</span><span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">]),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomSizeCrop</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">600</span><span class="p">),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
            <span class="p">])</span>
        <span class="p">),</span>
        <span class="n">normalize</span><span class="p">,</span>
    <span class="p">])</span>

<span class="k">if</span> <span class="n">image_set</span> <span class="o">==</span> <span class="s1">'val'</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">([</span><span class="mi">800</span><span class="p">],</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
        <span class="n">normalize</span><span class="p">,</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>DETR uses ImageNet standard-deviation and mean for the normalization.</p>
<p>For training dataloader, the transformations have <code>Random Horizontal Flip</code> and than it randomly selects between a <code>Random Resize</code> or collection of <code>Random Resize</code>, <code>Random Size Crop</code> and again <code>Random Resize</code>. The random resizing takes place at various scales of <em>[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]</em></p>
<p>Whereas for validation, the images are resized to width of 800, with the height of max 1333 and than normalized.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model-and-Training">
<a class="anchor" href="#Model-and-Training" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model and Training<a class="anchor-link" href="#Model-and-Training"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Fine-Tuning">
<a class="anchor" href="#Fine-Tuning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fine Tuning<a class="anchor-link" href="#Fine-Tuning"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># detr/main.py</span>

<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">resume</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">resume</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">'https'</span><span class="p">):</span> <span class="c1"># If argument is link</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span><span class="p">(</span>
                <span class="n">args</span><span class="o">.</span><span class="n">resume</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">,</span> <span class="n">check_hash</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">][</span><span class="s1">'class_embed.weight'</span><span class="p">]</span>
            <span class="k">del</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">'model'</span><span class="p">][</span><span class="s1">'class_embed.bias'</span><span class="p">]</span>
            <span class="n">strict_</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># To allow model to load without class_embed if num classes is different</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># if argument is .pth file</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">resume</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">)</span>
            <span class="n">strict_</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># Since we use our own pth, the num classes remain same, so strict loading</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We fine-tune(transfer learning) the <code>DETR-r50</code> model which is trained on COCO dataset, to learn on our Custom dataset.</p>
<p>The model which is trained on COCO has 91 classes, and the num_classes for DETR is 92 here, as DETR also have no-object class. But whereas our dataset only has 63 classes, we can reduce the final layer to 63 from 92. We could have also kept it to 92, as it wouldn't effect the result apart from slight increase in number of parameters as mentioned by the authors. As the weights won't take part in the prediction and would be just dead weights.</p>
<p>As we will see in the next part of Panoptic Segmentation, where the authors use 250 as number of classes, since it doesn't effect. Only thing to take care is num_classes must be atleast one greater than actual number of class.
</p>
<div class="flash flash-warn">
    <svg class="octicon octicon-zap octicon octicon-zap" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M10.561 1.5a.016.016 0 00-.01.004L3.286 8.571A.25.25 0 003.462 9H6.75a.75.75 0 01.694 1.034l-1.713 4.188 6.982-6.793A.25.25 0 0012.538 7H9.25a.75.75 0 01-.683-1.06l2.008-4.418.003-.006a.02.02 0 00-.004-.009.02.02 0 00-.006-.006L10.56 1.5zM9.504.43a1.516 1.516 0 012.437 1.713L10.415 5.5h2.123c1.57 0 2.346 1.909 1.22 3.004l-7.34 7.142a1.25 1.25 0 01-.871.354h-.302a1.25 1.25 0 01-1.157-1.723L5.633 10.5H3.462c-1.57 0-2.346-1.909-1.22-3.004L9.503.429z"></path></svg>
    <strong>Important: </strong>If our class ids are not continous for example if we have 3 classe with id <code>1</code>,<code>32</code> and <code>94</code>, than we will have to keep the <code>num_classes</code> as 95. The no-object class will be one greater than the <code>max_id</code> of the classes.
</div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dataset_file</span> <span class="o">==</span> <span class="s2">"construction"</span><span class="p">:</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">63</span><span class="o">+</span><span class="mi">1</span> <span class="c1"># 63 Classes + 1 for no object</span>
<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">dataset_file</span> <span class="o">==</span> <span class="s2">"construction_panoptic"</span><span class="p">:</span>
    <span class="c1"># for panoptic, we just add a num_classes that is large enough to hold</span>
    <span class="c1"># max_obj_id + 1, but the exact value doesn't really matter</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">63</span><span class="o">+</span><span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We had marked classes from 0 to 47 for <code>things</code> and from 48-63 for <code>stuff</code>, so for us the max_id for the classes is 63, hence we can give num_classes as <code>63+1</code>, where the 1 class at end is for <code>no-object</code></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">python</span> <span class="n">main</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">dataset_file</span> <span class="n">construction</span> <span class="o">--</span><span class="n">data_path</span> <span class="o">./</span><span class="n">datasets</span> \
        <span class="o">--</span><span class="n">device</span> <span class="n">cuda</span> <span class="o">--</span><span class="n">output_dir</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">output</span> <span class="o">--</span><span class="n">resume</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">dl</span><span class="o">.</span><span class="n">fbaipublicfiles</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">detr</span><span class="o">/</span><span class="n">detr</span><span class="o">-</span><span class="n">r50</span><span class="o">-</span><span class="n">e632da11</span><span class="o">.</span><span class="n">pth</span> \
        <span class="o">--</span><span class="n">epochs</span> <span class="o">&lt;</span><span class="n">number_of_epochs</span><span class="o">&gt;</span> <span class="o">--</span><span class="n">batch_size</span> <span class="o">&lt;</span><span class="n">batch_size</span><span class="o">&gt;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we see, we can pass link to <code>resume</code> argument, which is the pre trained weight of COCO, which is used to start the training from, and after each epoch, the weights of the epoch is saved in the <code>output</code> folder.</p>
<p>So, we can continue training from the last epoch, by passing the checkpoint weights path to the <code>resume</code> argument, and the training will start from the last epoch.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Inference-and-Metrics">
<a class="anchor" href="#Inference-and-Metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inference and Metrics<a class="anchor-link" href="#Inference-and-Metrics"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># detr/test.py</span>

<span class="n">orig_image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_sample</span><span class="p">)</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">make_coco_transforms</span><span class="p">(</span><span class="s2">"val"</span><span class="p">)</span> <span class="c1"># Resize to 800 and normalize</span>

<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="n">outputs</span><span class="p">[</span><span class="s2">"pred_logits"</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">"pred_logits"</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="c1"># Get Prediction Scores</span>
<span class="n">outputs</span><span class="p">[</span><span class="s2">"pred_boxes"</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">"pred_boxes"</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="c1"># Get Predtiction Bounding Boxes</span>

<span class="c1"># keep = probas.max(-1).values &gt; 0.85</span>
<span class="n">keep</span> <span class="o">=</span> <span class="n">probas</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="o">&gt;</span> <span class="n">args</span><span class="o">.</span><span class="n">thresh</span>

<span class="c1"># Rescale the predictions from 0,1 to image size</span>
<span class="n">bboxes_scaled</span> <span class="o">=</span> <span class="n">rescale_bboxes</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s1">'pred_boxes'</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <span class="n">keep</span><span class="p">],</span> <span class="n">orig_image</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> 

<span class="n">plot_bbox</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">bboxes_scaled</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Metrics">
<a class="anchor" href="#Metrics" aria-hidden="true"><span class="octicon octicon-link"></span></a>Metrics<a class="anchor-link" href="#Metrics"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="mAP-(mean-Average-Precision)">
<a class="anchor" href="#mAP-(mean-Average-Precision)" aria-hidden="true"><span class="octicon octicon-link"></span></a>mAP (mean Average Precision)<a class="anchor-link" href="#mAP-(mean-Average-Precision)"> </a>
</h3>
<p>In computer vision, mAP is a popular evaluation metric used for object detection.</p>
<p>Before understanding let's see what is Precision and Recall</p>
<p><code>Precision</code> measures how accurate your predictions are. i.e. the percentage of your predictions are correct. It measures how many of the predictions that your model made were actually correct.</p>
$$
Precision = \frac{TP}{TP+FP}
$$<p><code>Recall</code> measures how well you find all the positives i.e. for all the correct ground truth, the percetange of your predictions are correct.</p>
$$
Recall = \frac{TP}{TP+FN}
$$<p>We can see that the numerator for both Precision and Recall has <code>True Positives</code>, but the denominator changes for each. Both are equally important and depens on the application, and many times it's used in together by using harmonic mean for <code>F1-score</code> and so on.</p>
<blockquote>
<p>INFO:Excellent explanation on Precision and Recall with great examples - <a href="youtube.com/watch?v=O4joFUqvz40">YouTube Link</a></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In classification, getting True Positives, False Positives and False Negatives, is straight forward, where if the ground truth is cat, and the model predicted is cat, than it's a True Postive, where as if the model predicts cat and it's not a cat, which indicated False Positive, and if the model predicts not cat and it's a cat, which indicated False Negative.</p>
<p>In simpler words, its combination of did model predict correct (True/False), what is the class (Postive/Negative).</p>
<p>But how do we get all these in Object Detection, where the model not only finds the class but also the Bounding Box, and for that let's take a small de tour to understand IoU.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="IoU-(Intersection-over-Union)">
<a class="anchor" href="#IoU-(Intersection-over-Union)" aria-hidden="true"><span class="octicon octicon-link"></span></a>IoU (Intersection over Union)<a class="anchor-link" href="#IoU-(Intersection-over-Union)"> </a>
</h3>
<p>For each bounding box, we measure an overlap between the predicted bounding box and the ground truth bounding box. This is measured by <code>IoU</code>(intersection over union).<br>
Which is the <code>intersection</code> of the ground truth box with the predicted box, divided by the <code>union</code> of the ground truth box with the predicted box.</p>
$$
IoU = \frac{Area of intersection}{Area of union}
$$<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/IoU.jpg" alt="IoU"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now, since we know about IoU, in Object Detection, for True Positive, we assign a <code>threshold</code> to the IoU, and if the IoU is greater than the threshold, then it's a True Positive and if not, then it's a False Positive.</p>
<p>Let's say we have a ground truth bounding box of <code>[0,0,100,100]</code> and the model predicts a bounding box of <code>[50,50,100,100]</code>, then the IoU is <code>0.5</code>, which is less than the threshold of 0.5, so it's a False Positive when thresshold is 0.5. But the same predicted box will be a True Positive if the IoU is less than 0.5 say 0.3.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Average Precision (or even mean Average Precision) is the average over all categories of the precision at particular IoU threshold, and is denoted as <code>mAP@0.x</code>, where <code>0.x</code> is the IoU threshold.</p>
<p>We also have soemthing as <code>mAP@0.5:0.95:0.05</code> which is the mean over all APs ranging from 0.5 to 0.95 at every step of 0.05.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="mean-Average-Recall">
<a class="anchor" href="#mean-Average-Recall" aria-hidden="true"><span class="octicon octicon-link"></span></a>mean Average Recall<a class="anchor-link" href="#mean-Average-Recall"> </a>
</h3>
<p>Similarly, Average Recall is same as mAP with the use of Recall instead of precision</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Some-Cool-Sample-Results">
<a class="anchor" href="#Some-Cool-Sample-Results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Some Cool Sample Results<a class="anchor-link" href="#Some-Cool-Sample-Results"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/sample1.png" alt="Sample1"></p>
<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/sample2.png" alt="Sample2"></p>
<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/sample3.png" alt="Sample3"></p>
<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/sample4.png" alt="Sample4"></p>
<p><img src="/blog/images/copied_from_nb/../images/ObjectDetection/sample5.png" alt="Sample5"></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="abdksyed/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/02/ObjectDetection-DETR.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A place to explore thoughts.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/abdksyed" title="abdksyed"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/AI4AvgU" title="AI4AvgU"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
