<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>DE⫶TR – Extending Object Detection to Panoptic Segmentation | Explore Thoughts</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="DE⫶TR – Extending Object Detection to Panoptic Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An Extension to Object Detection using Transformers to Predict Pixel wise mask of each class." />
<meta property="og:description" content="An Extension to Object Detection using Transformers to Predict Pixel wise mask of each class." />
<link rel="canonical" href="https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/03/PanopticSegmentation-DETR.html" />
<meta property="og:url" content="https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/03/PanopticSegmentation-DETR.html" />
<meta property="og:site_name" content="Explore Thoughts" />
<meta property="og:image" content="https://abdksyed.github.io/blog/images/PanopticSegmentation/DETR.gif" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-03T00:00:00-05:00" />
<script type="application/ld+json">
{"image":"https://abdksyed.github.io/blog/images/PanopticSegmentation/DETR.gif","url":"https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/03/PanopticSegmentation-DETR.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://abdksyed.github.io/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/03/PanopticSegmentation-DETR.html"},"headline":"DE⫶TR – Extending Object Detection to Panoptic Segmentation","dateModified":"2021-10-03T00:00:00-05:00","datePublished":"2021-10-03T00:00:00-05:00","description":"An Extension to Object Detection using Transformers to Predict Pixel wise mask of each class.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://abdksyed.github.io/blog/feed.xml" title="Explore Thoughts" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Explore Thoughts</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">DE⫶TR -- Extending Object Detection to Panoptic Segmentation</h1><p class="page-description">An Extension to Object Detection using Transformers to Predict Pixel wise mask of each class.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-10-03T00:00:00-05:00" itemprop="datePublished">
        Oct 3, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#Custom Dataset">Custom Dataset</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Object Detection">Object Detection</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#Panoptic Segmentation">Panoptic Segmentation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#COCO">COCO</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#DETR">DETR</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/abdksyed/blog/tree/master/_notebooks/2021-10-03-PanopticSegmentation-DETR.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/abdksyed/blog/master?filepath=_notebooks%2F2021-10-03-PanopticSegmentation-DETR.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/abdksyed/blog/blob/master/_notebooks/2021-10-03-PanopticSegmentation-DETR.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Creating-Dataset-class-for-Panoptic-Segmentation">Creating Dataset class for Panoptic Segmentation </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Transformations">Transformations </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Model">Model </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Sending-to-Transformer">Sending to Transformer </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Some-Cool-Segmentations">Some Cool Segmentations </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-10-03-PanopticSegmentation-DETR.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/DETR.gif" alt="SuperCool"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Creating-Dataset-class-for-Panoptic-Segmentation">
<a class="anchor" href="#Creating-Dataset-class-for-Panoptic-Segmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating Dataset class for Panoptic Segmentation<a class="anchor-link" href="#Creating-Dataset-class-for-Panoptic-Segmentation"> </a>
</h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">ConstructionPanoptic</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_folder</span><span class="p">,</span> <span class="n">ann_folder</span><span class="p">,</span> <span class="n">ann_file</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_masks</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">ann_file</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coco</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="c1"># Readig the json file</span>

        <span class="c1"># sort 'images' field so that they are aligned with 'annotations'</span>
        <span class="c1"># i.e., in alphabetical order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">],</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'id'</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'annotations'</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'annotations'</span><span class="p">],</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">'image_id'</span><span class="p">])</span>
        <span class="c1"># sanity check, image names in images is same as in annotations masks.</span>
        <span class="k">if</span> <span class="s2">"annotations"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">ann</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'annotations'</span><span class="p">]):</span>
                <span class="c1">#print(img['file_name'], ann['file_name'])</span>
                <span class="k">assert</span> <span class="n">img</span><span class="p">[</span><span class="s1">'file_name'</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">ann</span><span class="p">[</span><span class="s1">'file_name'</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">img_folder</span> <span class="o">=</span> <span class="n">img_folder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ann_folder</span> <span class="o">=</span> <span class="n">ann_folder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ann_file</span> <span class="o">=</span> <span class="n">ann_file</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_masks</span> <span class="o">=</span> <span class="n">return_masks</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">ann_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'annotations'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span> <span class="k">if</span> <span class="s2">"annotations"</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">coco</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">img_ext</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">][</span><span class="n">idx</span><span class="p">][</span><span class="s1">'file_name'</span><span class="p">])</span><span class="o">.</span><span class="n">suffix</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_folder</span><span class="p">)</span> <span class="o">/</span> <span class="n">ann_info</span><span class="p">[</span><span class="s1">'file_name'</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'.png'</span><span class="p">,</span> <span class="n">img_ext</span><span class="p">)</span>
        <span class="n">ann_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ann_folder</span><span class="p">)</span> <span class="o">/</span> <span class="n">ann_info</span><span class="p">[</span><span class="s1">'file_name'</span><span class="p">]</span>

        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">'RGB'</span><span class="p">)</span>
        <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="s2">"segments_info"</span> <span class="ow">in</span> <span class="n">ann_info</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">ann_path</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">)</span> <span class="c1"># Read the mask file</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">rgb2id</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="c1"># Convert the mask to the id format</span>

            <span class="n">ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ann</span><span class="p">[</span><span class="s1">'id'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ann</span> <span class="ow">in</span> <span class="n">ann_info</span><span class="p">[</span><span class="s1">'segments_info'</span><span class="p">]])</span> <span class="c1"># Get the unique ids of classes in mask</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">masks</span> <span class="o">==</span> <span class="n">ids</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>

            <span class="n">masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">ann</span><span class="p">[</span><span class="s1">'category_id'</span><span class="p">]</span> <span class="k">for</span> <span class="n">ann</span> <span class="ow">in</span> <span class="n">ann_info</span><span class="p">[</span><span class="s1">'segments_info'</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>

        <span class="n">target</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">target</span><span class="p">[</span><span class="s1">'image_id'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">ann_info</span><span class="p">[</span><span class="s1">'image_id'</span><span class="p">]</span> <span class="k">if</span> <span class="s2">"image_id"</span> <span class="ow">in</span> <span class="n">ann_info</span> <span class="k">else</span> <span class="n">ann_info</span><span class="p">[</span><span class="s2">"id"</span><span class="p">]])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_masks</span><span class="p">:</span>
            <span class="n">target</span><span class="p">[</span><span class="s1">'masks'</span><span class="p">]</span> <span class="o">=</span> <span class="n">masks</span>
        <span class="n">target</span><span class="p">[</span><span class="s1">'labels'</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="c1"># Calculating BBox using mask, we already have BBox in annotations, we could have directly call ann_info['bbox']</span>
        <span class="n">target</span><span class="p">[</span><span class="s2">"boxes"</span><span class="p">]</span> <span class="o">=</span> <span class="n">masks_to_boxes</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="c1">#  target["boxes"] = ann_info['bbox']</span>

        <span class="n">target</span><span class="p">[</span><span class="s1">'size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">)])</span>
        <span class="n">target</span><span class="p">[</span><span class="s1">'orig_size'</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">)])</span>
        <span class="k">if</span> <span class="s2">"segments_info"</span> <span class="ow">in</span> <span class="n">ann_info</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'iscrowd'</span><span class="p">,</span> <span class="s1">'area'</span><span class="p">]:</span>
                <span class="n">target</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">ann</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">ann</span> <span class="ow">in</span> <span class="n">ann_info</span><span class="p">[</span><span class="s1">'segments_info'</span><span class="p">]])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_height_and_width</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">img_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coco</span><span class="p">[</span><span class="s1">'images'</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">img_info</span><span class="p">[</span><span class="s1">'height'</span><span class="p">]</span>
        <span class="n">width</span> <span class="o">=</span> <span class="n">img_info</span><span class="p">[</span><span class="s1">'width'</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For panoptic segmentation, we would want the dataset to return the image and the segmentation mask when we call the <code>__getitem__</code> method. We also return additoinal details like class label, bounding boxes, orignal size of the image as part of target along with the mask itself.</p>
<p>Also, if there are any transformations given, we apply those transformations on both the image and the mask.</p>
<p>As discussed in the <code>Creating Custom Dataset for DETR</code> post, the mask of the corresponding image should have the same name as the image with the suffix <code>.png</code> in the annotations folder.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Transformations">
<a class="anchor" href="#Transformations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transformations<a class="anchor-link" href="#Transformations"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="c1"># detr/datasets/construction.py</span>

<span class="kn">import</span> <span class="nn">datasets.transforms</span> <span class="k">as</span> <span class="nn">T</span>

<span class="n">normalize</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">T</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">])</span>

<span class="n">scales</span> <span class="o">=</span> <span class="p">[</span><span class="mi">480</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">544</span><span class="p">,</span> <span class="mi">576</span><span class="p">,</span> <span class="mi">608</span><span class="p">,</span> <span class="mi">640</span><span class="p">,</span> <span class="mi">672</span><span class="p">,</span> <span class="mi">704</span><span class="p">,</span> <span class="mi">736</span><span class="p">,</span> <span class="mi">768</span><span class="p">,</span> <span class="mi">800</span><span class="p">]</span>

<span class="k">if</span> <span class="n">image_set</span> <span class="o">==</span> <span class="s1">'train'</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">T</span><span class="o">.</span><span class="n">RandomSelect</span><span class="p">(</span>
            <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
            <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">([</span><span class="mi">400</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">600</span><span class="p">]),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomSizeCrop</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">600</span><span class="p">),</span>
                <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">(</span><span class="n">scales</span><span class="p">,</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
            <span class="p">])</span>
        <span class="p">),</span>
        <span class="n">normalize</span><span class="p">,</span>
    <span class="p">])</span>

<span class="k">if</span> <span class="n">image_set</span> <span class="o">==</span> <span class="s1">'val'</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">T</span><span class="o">.</span><span class="n">RandomResize</span><span class="p">([</span><span class="mi">800</span><span class="p">],</span> <span class="n">max_size</span><span class="o">=</span><span class="mi">1333</span><span class="p">),</span>
        <span class="n">normalize</span><span class="p">,</span>
    <span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>DETR uses ImageNet standard-deviation and mean for the normalization.</p>
<p>For training dataloader, the transformations have <code>Random Horizontal Flip</code> and than it randomly selects between a <code>Random Resize</code> or collection of <code>Random Resize</code>, <code>Random Size Crop</code> and again <code>Random Resize</code>. The random resizing takes place at various scales of <em>[480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]</em></p>
<p>Whereas for validation, the images are resized to width of 800, with the height of max 1333 and than normalized.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Model">
<a class="anchor" href="#Model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model<a class="anchor-link" href="#Model"> </a>
</h1>
<p>The DETR model for the Panoptic Segmentation, remains same as the DETR model for the Object Detection, with an addition of mask head after the decoder part. Let's explore the model pipeline, how we use backbone(ResNet-50) generated features at every stage in the mask head.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A standard CNN is used to extract a compact feature representation of the image. Here a pre-trained ResNet50 model was used, and the features after the 5th block were extracted where the size of the image is compacted to <em>H</em>. <em>W</em> but with <em>2048</em> channels. Where <em>H</em> is <em>H<sub>0</sub>/32</em>, <em>W</em> is <em>W<sub>0</sub>/32</em> and <em>H<sub>0</sub></em> &amp; <em>W<sub>0</sub></em> are the <em>initial Height</em> and <em>Width</em> of the Image. A <em>Conv2d</em> is used to bring down the channels size from <em>2048</em> to <em>256</em></p>
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/1_CNN_Backbone.png" alt="CNN Features"></p>
<p>While the forward pass of the ResNet, the activation maps after each block of <code>Res2</code>(<em>H<sub>0</sub>/4</em> x  <em>W<sub>0</sub>/4</em> x 128), <code>Res3</code>(<em>H<sub>0</sub>/8</em> x  <em>W<sub>0</sub>/8</em>x 256), <code>Res4</code>(<em>H<sub>0</sub>/16</em> x  <em>W<sub>0</sub>/16</em> x 512) and <code>Res5</code>(<em>H<sub>0</sub>/32</em> x  <em>W<sub>0</sub>/32</em> x 1028) are saved and set aside for the images which are to be used in the Panoptic segmentation down the line.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sending-to-Transformer">
<a class="anchor" href="#Sending-to-Transformer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sending to Transformer<a class="anchor-link" href="#Sending-to-Transformer"> </a>
</h2>
<p>The resultant compact features are now sent to the Transformer encoder-decoder architecture. But since Transformers expect sequential inputs, the compact features of size <em>HxWx256</em> is flattened out to be HWx256 (in PyTorch, the tensor is 256xHxW, so after flattening to 256xHW, it is also transposed to HWx256)</p>
<p>In comparison to ViT where the Image is converted 196x768 embedding for 224x224 image, here the embedding we get is 196x256 (as after Res5 block, we have map size of 14x14 as HxW, so flattening it out gives 196 and we have 256 channels, giving embedding of 196x256).</p>
<p>As we discuees in the DETR part, Transformers are permutation equivariant, which in simpler terms means that the Transformers are not aware of the 2D structure of the image, permuting the inputs just permutes the outputs, and have no effect. So we will have to make sure to add some positional awareness to the inputs.</p>
<p>And this can be done in several ways, one way to do is adding learnable parameters to the input embeddings, where the networks will learn the positional encodings and the other way, as done in original Transformer, is adding some kind of fixed positional embedding like one-hot encoding or using some type of mathematical functions like <em>sin</em> functions with respect to the input patch position to generate the positional embedding. In DETR with empirical results the showed that the <em>sin</em> encodings had marginal better results than learnt embeddings, so these were used in the process.</p>
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/2_Img2Embedding.png" alt="Image Embeddings"></p>
<p>After we get the Image embeddings, we can send to a Transformer Encoder, here we have 6 layers of encoders, where output of one encoder is sent as input to other, to increase the model capacity and improve training.</p>
<p>Since the transformers, work on sequence and maintain the sequence length, the input is a sequence of image patches and the output of all the encoders are also patches which can be again converted to form/shape of an image, so here after the image is encoded throught the encoder, we save the encoded image separately for further usage(which we will see soon in mask head part), and the sequence is sent to the decoder</p>
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/7_Encoded_Image.png" alt="Encoder"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Some-Cool-Segmentations">
<a class="anchor" href="#Some-Cool-Segmentations" aria-hidden="true"><span class="octicon octicon-link"></span></a>Some Cool Segmentations<a class="anchor-link" href="#Some-Cool-Segmentations"> </a>
</h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/sample1.png" alt="Sample1"></p>
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/sample2.png" alt="Sample2"></p>
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/sample3.png" alt="Sample3"></p>
<p><img src="/blog/images/copied_from_nb/../images/PanopticSegmentation/sample4.png" alt="Sample4"></p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="abdksyed/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/custom%20dataset/object%20detection/panoptic%20segmentation/coco/detr/2021/10/03/PanopticSegmentation-DETR.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A place to explore thoughts.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/abdksyed" title="abdksyed"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/AI4AvgU" title="AI4AvgU"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
